{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from net.yolo_top import yolov3\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from net.config import cfg\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from predict.draw_box import draw_boxes\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class YOLO_PREDICT:\n",
    "    \n",
    "    def __init__(self, gpu = \"0\"):\n",
    "        \n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "        \n",
    "        # clear graph\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # now, in predict mode\n",
    "        self.istraining = tf.constant(False, tf.bool)\n",
    "        # which size is the training size\n",
    "        self.img_size = cfg.data.img_size\n",
    "        # \n",
    "        self.batch_size = cfg.predict.batch_size\n",
    "        self.scratch = cfg.predict.scratch\n",
    "        \n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        self.img_hw = tf.placeholder(dtype=tf.float32, shape=[2])\n",
    "        self.imgs_holder = tf.placeholder(tf.float32, \n",
    "                                          shape = [None,\n",
    "                                                   self.img_size[0], \n",
    "                                                   self.img_size[1], \n",
    "                                                   self.img_size[2]])\n",
    "        \n",
    "        self.model = yolov3(self.imgs_holder, None, self.istraining)\n",
    "        self.boxes, self.scores, self.classes = self.model.pedict(self.img_hw,\n",
    "                                                                  iou_threshold = cfg.predict.iou_thresh,\n",
    "                                                                  score_threshold = cfg.predict.score_thresh)\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.ckpt_dir = cfg.path.ckpt_dir\n",
    "        \n",
    "    def predict_imgs(self, image_data, img_id_list):\n",
    "    \n",
    "        boxes_dict = {}\n",
    "        scores_dict = {}\n",
    "        classes_dict = {}\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            ckpt = tf.train.get_checkpoint_state(self.ckpt_dir)\n",
    "            self.saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            for i, single_image_data in enumerate(image_data):\n",
    "                boxes_, scores_, classes_ = sess.run([self.boxes, self.scores, self.classes],\n",
    "                                                     feed_dict={\n",
    "                                                        self.img_hw:\n",
    "                                                         [self.img_size[1], \n",
    "                                                          self.img_size[0]],\n",
    "                                                        self.imgs_holder: \n",
    "                                                         np.reshape(single_image_data / 255, \n",
    "                                                            [1, \n",
    "                                                             self.img_size[0], \n",
    "                                                             self.img_size[1], \n",
    "                                                             self.img_size[2]])})\n",
    "                if (boxes.shape[0] == 0):\n",
    "                    print(boxes_.shape)\n",
    "                    boxes = boxes_[np.newaxis, :]\n",
    "                    scores = scores_[np.newaxis, :]\n",
    "                    classes = classes_[np.newaxis, :]\n",
    "                else:\n",
    "                    boxes = np.concatenate((boxes, boxes_[np.newaxis, :]))\n",
    "                    scores = np.concatenate((scores, scores_[np.newaxis, :]))\n",
    "                    classes = np.concatenate((classes, classes_[np.newaxis, :]))\n",
    "                \n",
    "                boxes_dict[img_id_list[i]] = boxes_\n",
    "                scores_dict[img_id_list[i]] = scores_\n",
    "                classes_dict[img_id_list[i]] = classes_\n",
    "        \n",
    "        return boxes_dict, scores_dict, classes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 608, 608, 3)\n"
     ]
    }
   ],
   "source": [
    "img_resize = cfg.train.image_resized\n",
    "image_test = Image.open('dog.jpg')\n",
    "resized_image = image_test.resize((img_resize, img_resize), Image.BICUBIC)\n",
    "image_data1 = np.array(resized_image, dtype='float32')\n",
    "\n",
    "image_test = Image.open('test.jpg')\n",
    "resized_image = image_test.resize((img_resize, img_resize), Image.BICUBIC)\n",
    "image_data2 = np.array(resized_image, dtype='float32')\n",
    "\n",
    "image_data = np.stack((image_data2, image_data1))\n",
    "print(image_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darknet\n",
      "(?, 608, 608, 3)\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt/yolov3.ckpt-50001\n",
      "(5, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-000f33f15419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO_PREDICT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-3fb9df4efb22>\u001b[0m in \u001b[0;36mpredict_imgs\u001b[0;34m(self, image_data)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "model_predict = YOLO_PREDICT(gpu = \"0\")\n",
    "model_predict.predict_imgs(image_data, img_id_list = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
